{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f53ddf9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-18T21:18:47.404259Z",
     "iopub.status.busy": "2024-08-18T21:18:47.403745Z",
     "iopub.status.idle": "2024-08-18T21:18:51.170333Z",
     "shell.execute_reply": "2024-08-18T21:18:51.169093Z"
    },
    "papermill": {
     "duration": 3.780194,
     "end_time": "2024-08-18T21:18:51.173075",
     "exception": false,
     "start_time": "2024-08-18T21:18:47.392881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer,KNNImputer\n",
    "from sklearn.preprocessing import QuantileTransformer, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,StratifiedShuffleSplit\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 500)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66b0a534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:18:51.192203Z",
     "iopub.status.busy": "2024-08-18T21:18:51.191588Z",
     "iopub.status.idle": "2024-08-18T21:19:15.576023Z",
     "shell.execute_reply": "2024-08-18T21:19:15.574821Z"
    },
    "papermill": {
     "duration": 24.397071,
     "end_time": "2024-08-18T21:19:15.578833",
     "exception": false,
     "start_time": "2024-08-18T21:18:51.181762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('/kaggle/input/playground-series-s4e8/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e8/test.csv')\n",
    "train['dataset'] = 'train'\n",
    "test['dataset'] = 'test'\n",
    "\n",
    "\n",
    "df_ = pd.concat([train, test], sort=False)\n",
    "df=df_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f10bb51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:19:15.597644Z",
     "iopub.status.busy": "2024-08-18T21:19:15.596717Z",
     "iopub.status.idle": "2024-08-18T21:19:18.217720Z",
     "shell.execute_reply": "2024-08-18T21:19:18.216589Z"
    },
    "papermill": {
     "duration": 2.63333,
     "end_time": "2024-08-18T21:19:18.220495",
     "exception": false,
     "start_time": "2024-08-18T21:19:15.587165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['class'] = df['class'].replace({'e': 0, 'p': 1 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1489f085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:19:18.237711Z",
     "iopub.status.busy": "2024-08-18T21:19:18.237075Z",
     "iopub.status.idle": "2024-08-18T21:19:18.265920Z",
     "shell.execute_reply": "2024-08-18T21:19:18.264945Z"
    },
    "papermill": {
     "duration": 0.039589,
     "end_time": "2024-08-18T21:19:18.268066",
     "exception": false,
     "start_time": "2024-08-18T21:19:18.228477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>4.51</td>\n",
       "      <td>15.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>4.79</td>\n",
       "      <td>6.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.94</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>b</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>6.85</td>\n",
       "      <td>9.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l</td>\n",
       "      <td>w</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.88</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>4.16</td>\n",
       "      <td>6.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.85</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>w</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>3.37</td>\n",
       "      <td>8.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  class  cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed gill-attachment gill-spacing gill-color  stem-height  stem-width stem-root stem-surface stem-color veil-type veil-color has-ring ring-type spore-print-color habitat season dataset\n",
       "0   0    0.0          8.80         f           s         u                    f               a            c          w         4.51       15.39       NaN          NaN          w       NaN        NaN        f         f               NaN       d      a   train\n",
       "1   1    1.0          4.51         x           h         o                    f               a            c          n         4.79        6.48       NaN            y          o       NaN        NaN        t         z               NaN       d      w   train\n",
       "2   2    0.0          6.94         f           s         b                    f               x            c          w         6.85        9.93       NaN            s          n       NaN        NaN        f         f               NaN       l      w   train\n",
       "3   3    0.0          3.88         f           y         g                    f               s          NaN          g         4.16        6.53       NaN          NaN          w       NaN        NaN        f         f               NaN       d      u   train\n",
       "4   4    0.0          5.85         x           l         w                    f               d          NaN          w         3.37        8.36       NaN          NaN          w       NaN        NaN        f         f               NaN       g      a   train"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66141743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:19:18.286665Z",
     "iopub.status.busy": "2024-08-18T21:19:18.286317Z",
     "iopub.status.idle": "2024-08-18T21:19:23.522840Z",
     "shell.execute_reply": "2024-08-18T21:19:23.521733Z"
    },
    "papermill": {
     "duration": 5.248751,
     "end_time": "2024-08-18T21:19:23.525306",
     "exception": false,
     "start_time": "2024-08-18T21:19:18.276555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id  :  5194909\n",
      "class  :  2\n",
      "cap-diameter  :  4145\n",
      "cap-shape  :  108\n",
      "cap-surface  :  114\n",
      "cap-color  :  109\n",
      "does-bruise-or-bleed  :  29\n",
      "gill-attachment  :  117\n",
      "gill-spacing  :  66\n",
      "gill-color  :  86\n",
      "stem-height  :  2858\n",
      "stem-width  :  6194\n",
      "stem-root  :  45\n",
      "stem-surface  :  87\n",
      "stem-color  :  88\n",
      "veil-type  :  24\n",
      "veil-color  :  27\n",
      "has-ring  :  26\n",
      "ring-type  :  47\n",
      "spore-print-color  :  43\n",
      "habitat  :  65\n",
      "season  :  4\n",
      "dataset  :  2\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns :\n",
    "    print (col,\" : \",df[col].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49949464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:19:23.544464Z",
     "iopub.status.busy": "2024-08-18T21:19:23.544103Z",
     "iopub.status.idle": "2024-08-18T21:19:46.028540Z",
     "shell.execute_reply": "2024-08-18T21:19:46.027304Z"
    },
    "papermill": {
     "duration": 22.496601,
     "end_time": "2024-08-18T21:19:46.031022",
     "exception": false,
     "start_time": "2024-08-18T21:19:23.534421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id     Ratio\n",
      "id                   \n",
      "0         1  0.000019\n",
      "3463271   1  0.000019\n",
      "3463278   1  0.000019\n",
      "3463277   1  0.000019\n",
      "3463276   1  0.000019\n",
      "...      ..       ...\n",
      "1731635   1  0.000019\n",
      "1731634   1  0.000019\n",
      "1731633   1  0.000019\n",
      "1731632   1  0.000019\n",
      "5194908   1  0.000019\n",
      "\n",
      "[5194909 rows x 2 columns]\n",
      "##########################################\n",
      "         class      Ratio\n",
      "class                    \n",
      "1.0    1705396  32.828217\n",
      "0.0    1411549  27.171775\n",
      "##########################################\n",
      "              cap-diameter     Ratio\n",
      "cap-diameter                        \n",
      "1.49                 13638  0.262526\n",
      "3.18                 13116  0.252478\n",
      "3.14                 12317  0.237098\n",
      "1.51                 11792  0.226991\n",
      "3.28                 11403  0.219503\n",
      "...                    ...       ...\n",
      "30.81                    1  0.000019\n",
      "44.48                    1  0.000019\n",
      "32.50                    1  0.000019\n",
      "38.29                    1  0.000019\n",
      "58.98                    1  0.000019\n",
      "\n",
      "[4145 rows x 2 columns]\n",
      "##########################################\n",
      "           cap-shape      Ratio\n",
      "cap-shape                      \n",
      "x            2393975  46.083098\n",
      "f            1128598  21.725077\n",
      "s             607844  11.700763\n",
      "b             530525  10.212402\n",
      "o             180807   3.480465\n",
      "...              ...        ...\n",
      "3.25               1   0.000019\n",
      "3.37               1   0.000019\n",
      "1.66               1   0.000019\n",
      "9.13               1   0.000019\n",
      "4.54               1   0.000019\n",
      "\n",
      "[108 rows x 2 columns]\n",
      "##########################################\n",
      "             cap-surface      Ratio\n",
      "cap-surface                        \n",
      "t                 767629  14.776563\n",
      "s                 642160  12.361333\n",
      "y                 546162  10.513408\n",
      "h                 474197   9.128110\n",
      "g                 439869   8.467309\n",
      "...                  ...        ...\n",
      "14.04                  1   0.000019\n",
      "8.96                   1   0.000019\n",
      "10.83                  1   0.000019\n",
      "has h                  1   0.000019\n",
      "5.1                    1   0.000019\n",
      "\n",
      "[114 rows x 2 columns]\n",
      "##########################################\n",
      "            cap-color      Ratio\n",
      "cap-color                       \n",
      "n             2263849  43.578222\n",
      "y              645689  12.429265\n",
      "w              633286  12.190512\n",
      "g              351506   6.766355\n",
      "e              328814   6.329543\n",
      "...               ...        ...\n",
      "5.41                1   0.000019\n",
      "6.9                 1   0.000019\n",
      "veil-color          1   0.000019\n",
      "5.25                1   0.000019\n",
      "9.19                1   0.000019\n",
      "\n",
      "[109 rows x 2 columns]\n",
      "##########################################\n",
      "                      does-bruise-or-bleed      Ratio\n",
      "does-bruise-or-bleed                                 \n",
      "f                                  4283405  82.453899\n",
      "t                                   911312  17.542405\n",
      "w                                       21   0.000404\n",
      "x                                       18   0.000346\n",
      "c                                       14   0.000269\n",
      "s                                       13   0.000250\n",
      "h                                       13   0.000250\n",
      "a                                        9   0.000173\n",
      "k                                        9   0.000173\n",
      "p                                        9   0.000173\n",
      "b                                        9   0.000173\n",
      "y                                        8   0.000154\n",
      "e                                        7   0.000135\n",
      "o                                        6   0.000115\n",
      "n                                        6   0.000115\n",
      "g                                        6   0.000115\n",
      "l                                        5   0.000096\n",
      "d                                        4   0.000077\n",
      "i                                        3   0.000058\n",
      "z                                        3   0.000058\n",
      "r                                        2   0.000038\n",
      "m                                        2   0.000038\n",
      "3.43                                     1   0.000019\n",
      "has-ring                                 1   0.000019\n",
      "4.42                                     1   0.000019\n",
      "2.9                                      1   0.000019\n",
      "u                                        1   0.000019\n",
      "season                                   1   0.000019\n",
      "does t                                   1   0.000019\n",
      "##########################################\n",
      "                 gill-attachment      Ratio\n",
      "gill-attachment                            \n",
      "a                        1076994  20.731720\n",
      "d                         981820  18.899657\n",
      "x                         601636  11.581262\n",
      "e                         503134   9.685136\n",
      "s                         491718   9.465382\n",
      "...                          ...        ...\n",
      "2.41                           1   0.000019\n",
      "8.47                           1   0.000019\n",
      "has d                          1   0.000019\n",
      "11.62                          1   0.000019\n",
      "is None                        1   0.000019\n",
      "\n",
      "[117 rows x 2 columns]\n",
      "##########################################\n",
      "              gill-spacing      Ratio\n",
      "gill-spacing                         \n",
      "c                  2218030  42.696224\n",
      "d                   680017  13.090066\n",
      "f                   198603   3.823031\n",
      "e                       35   0.000674\n",
      "a                       27   0.000520\n",
      "...                    ...        ...\n",
      "3.81                     1   0.000019\n",
      "4.09                     1   0.000019\n",
      "1.36                     1   0.000019\n",
      "3.24                     1   0.000019\n",
      "18.89                    1   0.000019\n",
      "\n",
      "[66 rows x 2 columns]\n",
      "##########################################\n",
      "            gill-color      Ratio\n",
      "gill-color                       \n",
      "w              1552311  29.881390\n",
      "n               905555  17.431585\n",
      "y               783396  15.080072\n",
      "p               572781  11.025814\n",
      "g               353683   6.808262\n",
      "...                ...        ...\n",
      "is y                 1   0.000019\n",
      "e y                  1   0.000019\n",
      "1.91                 1   0.000019\n",
      "does n               1   0.000019\n",
      "2.83                 1   0.000019\n",
      "\n",
      "[86 rows x 2 columns]\n",
      "##########################################\n",
      "             stem-height     Ratio\n",
      "stem-height                       \n",
      "5.24               20496  0.394540\n",
      "5.92               19639  0.378043\n",
      "5.32               18230  0.350920\n",
      "5.35               17413  0.335194\n",
      "5.99               17343  0.333846\n",
      "...                  ...       ...\n",
      "34.05                  1  0.000019\n",
      "49.03                  1  0.000019\n",
      "34.35                  1  0.000019\n",
      "31.51                  1  0.000019\n",
      "38.40                  1  0.000019\n",
      "\n",
      "[2858 rows x 2 columns]\n",
      "##########################################\n",
      "            stem-width     Ratio\n",
      "stem-width                      \n",
      "2.41             13007  0.250380\n",
      "2.45             12190  0.234653\n",
      "2.49             11751  0.226202\n",
      "2.56             11439  0.220196\n",
      "2.47             11274  0.217020\n",
      "...                ...       ...\n",
      "83.28                1  0.000019\n",
      "53.06                1  0.000019\n",
      "57.70                1  0.000019\n",
      "56.88                1  0.000019\n",
      "51.97                1  0.000019\n",
      "\n",
      "[6194 rows x 2 columns]\n",
      "##########################################\n",
      "                   stem-root     Ratio\n",
      "stem-root                             \n",
      "b                     276382  5.320247\n",
      "s                     195199  3.757506\n",
      "r                      79409  1.528593\n",
      "c                      47617  0.916609\n",
      "f                        971  0.018691\n",
      "d                         31  0.000597\n",
      "y                         28  0.000539\n",
      "g                         26  0.000500\n",
      "p                         23  0.000443\n",
      "w                         18  0.000346\n",
      "l                         16  0.000308\n",
      "u                         16  0.000308\n",
      "k                         16  0.000308\n",
      "t                         16  0.000308\n",
      "e                         13  0.000250\n",
      "x                         12  0.000231\n",
      "a                         12  0.000231\n",
      "i                         11  0.000212\n",
      "n                         11  0.000212\n",
      "o                         10  0.000192\n",
      "h                          5  0.000096\n",
      "m                          5  0.000096\n",
      "z                          4  0.000077\n",
      "1.48                       2  0.000038\n",
      "spore-print-color          1  0.000019\n",
      "3.59                       1  0.000019\n",
      "2.82                       1  0.000019\n",
      "13.46                      1  0.000019\n",
      "3.24                       1  0.000019\n",
      "18.29                      1  0.000019\n",
      "1.62                       1  0.000019\n",
      "7.15                       1  0.000019\n",
      "13.03                      1  0.000019\n",
      "3.49                       1  0.000019\n",
      "3.63                       1  0.000019\n",
      "10.87                      1  0.000019\n",
      "18.06                      1  0.000019\n",
      "20.0                       1  0.000019\n",
      "5.59                       1  0.000019\n",
      "3.23                       1  0.000019\n",
      "15.69                      1  0.000019\n",
      "16.88                      1  0.000019\n",
      "2.77                       1  0.000019\n",
      "20.01                      1  0.000019\n",
      "24.73                      1  0.000019\n",
      "##########################################\n",
      "              stem-surface      Ratio\n",
      "stem-surface                         \n",
      "s                   546106  10.512330\n",
      "y                   424962   8.180355\n",
      "i                   373538   7.190463\n",
      "t                   246956   4.753808\n",
      "g                   129928   2.501064\n",
      "...                    ...        ...\n",
      "49.46                    1   0.000019\n",
      "19.35                    1   0.000019\n",
      "2.68                     1   0.000019\n",
      "4.74                     1   0.000019\n",
      "6.59                     1   0.000019\n",
      "\n",
      "[87 rows x 2 columns]\n",
      "##########################################\n",
      "            stem-color      Ratio\n",
      "stem-color                       \n",
      "w              1994002  38.383771\n",
      "n              1671620  32.178042\n",
      "y               624112  12.013916\n",
      "g               220221   4.239170\n",
      "o               186635   3.592652\n",
      "...                ...        ...\n",
      "6.09                 1   0.000019\n",
      "3.56                 1   0.000019\n",
      "3.37                 1   0.000019\n",
      "4.62                 1   0.000019\n",
      "3.02                 1   0.000019\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "##########################################\n",
      "           veil-type     Ratio\n",
      "veil-type                     \n",
      "u             265746  5.115508\n",
      "w                 23  0.000443\n",
      "e                 14  0.000269\n",
      "a                 11  0.000212\n",
      "k                  9  0.000173\n",
      "f                  8  0.000154\n",
      "c                  7  0.000135\n",
      "g                  7  0.000135\n",
      "y                  7  0.000135\n",
      "n                  6  0.000115\n",
      "b                  6  0.000115\n",
      "s                  6  0.000115\n",
      "p                  5  0.000096\n",
      "i                  2  0.000038\n",
      "d                  2  0.000038\n",
      "h                  2  0.000038\n",
      "r                  2  0.000038\n",
      "l                  2  0.000038\n",
      "5.94               1  0.000019\n",
      "11                 1  0.000019\n",
      "t                  1  0.000019\n",
      "is None            1  0.000019\n",
      "21.11              1  0.000019\n",
      "m                  1  0.000019\n",
      "##########################################\n",
      "            veil-color     Ratio\n",
      "veil-color                      \n",
      "w               465502  8.960734\n",
      "y                51255  0.986639\n",
      "n                50295  0.968159\n",
      "u                23439  0.451192\n",
      "k                21786  0.419372\n",
      "e                15316  0.294827\n",
      "g                   50  0.000962\n",
      "p                   41  0.000789\n",
      "r                   22  0.000423\n",
      "o                   18  0.000346\n",
      "s                   17  0.000327\n",
      "t                   16  0.000308\n",
      "d                   15  0.000289\n",
      "h                   12  0.000231\n",
      "a                   11  0.000212\n",
      "i                   10  0.000192\n",
      "f                    8  0.000154\n",
      "b                    7  0.000135\n",
      "l                    6  0.000115\n",
      "c                    5  0.000096\n",
      "8.25                 1  0.000019\n",
      "2.49                 1  0.000019\n",
      "z                    1  0.000019\n",
      "3.32                 1  0.000019\n",
      "4.02                 1  0.000019\n",
      "m                    1  0.000019\n",
      "9                    1  0.000019\n",
      "##########################################\n",
      "            has-ring      Ratio\n",
      "has-ring                       \n",
      "f            3946912  75.976538\n",
      "t            1247741  24.018534\n",
      "r                 27   0.000520\n",
      "h                 21   0.000404\n",
      "c                 20   0.000385\n",
      "e                 20   0.000385\n",
      "g                 17   0.000327\n",
      "p                 16   0.000308\n",
      "l                 16   0.000308\n",
      "s                 15   0.000289\n",
      "z                  9   0.000173\n",
      "x                  8   0.000154\n",
      "d                  8   0.000154\n",
      "m                  6   0.000115\n",
      "y                  5   0.000096\n",
      "a                  5   0.000096\n",
      "o                  4   0.000077\n",
      "k                  3   0.000058\n",
      "i                  3   0.000058\n",
      "n                  2   0.000038\n",
      "w                  2   0.000038\n",
      "b                  2   0.000038\n",
      "f has-ring         1   0.000019\n",
      "10.3               1   0.000019\n",
      "u                  1   0.000019\n",
      "20.96              1   0.000019\n",
      "##########################################\n",
      "                      ring-type      Ratio\n",
      "ring-type                                 \n",
      "f                       4127370  79.450285\n",
      "e                        200354   3.856737\n",
      "z                        189697   3.651594\n",
      "l                        122290   2.354035\n",
      "p                        113332   2.181597\n",
      "r                        113309   2.181155\n",
      "g                        106159   2.043520\n",
      "m                          6681   0.128607\n",
      "t                           144   0.002772\n",
      "d                            61   0.001174\n",
      "x                            53   0.001020\n",
      "n                            50   0.000962\n",
      "y                            41   0.000789\n",
      "b                            41   0.000789\n",
      "w                            31   0.000597\n",
      "s                            30   0.000577\n",
      "a                            29   0.000558\n",
      "u                            27   0.000520\n",
      "c                            24   0.000462\n",
      "k                            22   0.000423\n",
      "h                            20   0.000385\n",
      "o                            18   0.000346\n",
      "ring-type                    11   0.000212\n",
      "i                             8   0.000154\n",
      "season                        4   0.000077\n",
      "does f                        4   0.000077\n",
      "1                             2   0.000038\n",
      "2                             2   0.000038\n",
      "spore-print-color             2   0.000038\n",
      "3.12                          1   0.000019\n",
      "2.87                          1   0.000019\n",
      "18.5                          1   0.000019\n",
      "8.12                          1   0.000019\n",
      "10.36                         1   0.000019\n",
      "12.63                         1   0.000019\n",
      "is p                          1   0.000019\n",
      "3.48                          1   0.000019\n",
      "8.25                          1   0.000019\n",
      "class                         1   0.000019\n",
      "sp                            1   0.000019\n",
      "15                            1   0.000019\n",
      "14                            1   0.000019\n",
      "23.6                          1   0.000019\n",
      "11                            1   0.000019\n",
      "does-bruise-or-bleed          1   0.000019\n",
      "4                             1   0.000019\n",
      "9.33                          1   0.000019\n",
      "##########################################\n",
      "                   spore-print-color     Ratio\n",
      "spore-print-color                             \n",
      "k                             178883  3.443429\n",
      "p                             113689  2.188470\n",
      "w                              83830  1.613695\n",
      "n                              37727  0.726230\n",
      "r                              13280  0.255635\n",
      "u                              12101  0.232940\n",
      "g                               5815  0.111937\n",
      "y                                 54  0.001039\n",
      "s                                 31  0.000597\n",
      "f                                 25  0.000481\n",
      "e                                 23  0.000443\n",
      "a                                 19  0.000366\n",
      "c                                 19  0.000366\n",
      "t                                 18  0.000346\n",
      "d                                 15  0.000289\n",
      "l                                 13  0.000250\n",
      "b                                 12  0.000231\n",
      "o                                 11  0.000212\n",
      "h                                  6  0.000115\n",
      "i                                  5  0.000096\n",
      "z                                  5  0.000096\n",
      "m                                  4  0.000077\n",
      "veil-color                         3  0.000058\n",
      "x                                  3  0.000058\n",
      "9 None                             1  0.000019\n",
      "8.82                               1  0.000019\n",
      "4                                  1  0.000019\n",
      "3.65                               1  0.000019\n",
      "26.48                              1  0.000019\n",
      "2.49                               1  0.000019\n",
      "ring-type                          1  0.000019\n",
      "27.48                              1  0.000019\n",
      "6.14                               1  0.000019\n",
      "2.52                               1  0.000019\n",
      "10 None                            1  0.000019\n",
      "17.72                              1  0.000019\n",
      "4.58                               1  0.000019\n",
      "6.36                               1  0.000019\n",
      "9.55                               1  0.000019\n",
      "season                             1  0.000019\n",
      "2.62                               1  0.000019\n",
      "class                              1  0.000019\n",
      "2.92                               1  0.000019\n",
      "##########################################\n",
      "           habitat      Ratio\n",
      "habitat                      \n",
      "d          3627993  69.837470\n",
      "g           759208  14.614462\n",
      "l           286350   5.512127\n",
      "m           252227   4.855273\n",
      "h           200169   3.853176\n",
      "...            ...        ...\n",
      "3.11             1   0.000019\n",
      "16.46            1   0.000019\n",
      "7.37             1   0.000019\n",
      "veil-type        1   0.000019\n",
      "3.19             1   0.000019\n",
      "\n",
      "[65 rows x 2 columns]\n",
      "##########################################\n",
      "         season      Ratio\n",
      "season                    \n",
      "a       2572406  49.517826\n",
      "u       1921855  36.994969\n",
      "w        464164   8.934978\n",
      "s        236484   4.552226\n",
      "##########################################\n",
      "         dataset      Ratio\n",
      "dataset                    \n",
      "train    3116945  59.999992\n",
      "test     2077964  40.000008\n",
      "##########################################\n"
     ]
    }
   ],
   "source": [
    "for col_name in df.columns :\n",
    "     print(pd.DataFrame({col_name: df[col_name].value_counts(),\"Ratio\": 100 * df[col_name].value_counts() / len(df)}))\n",
    "     print(\"##########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "887b44d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:19:46.055110Z",
     "iopub.status.busy": "2024-08-18T21:19:46.054115Z",
     "iopub.status.idle": "2024-08-18T21:20:09.951646Z",
     "shell.execute_reply": "2024-08-18T21:20:09.950438Z"
    },
    "papermill": {
     "duration": 23.912309,
     "end_time": "2024-08-18T21:20:09.954334",
     "exception": false,
     "start_time": "2024-08-18T21:19:46.042025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       n_miss  ratio\n",
      "veil-type             4929038  94.88\n",
      "spore-print-color     4749299  91.42\n",
      "stem-root             4595035  88.45\n",
      "veil-color            4567071  87.91\n",
      "stem-surface          3302349  63.57\n",
      "gill-spacing          2098030  40.39\n",
      "class                 2077964  40.00\n",
      "cap-surface           1117927  21.52\n",
      "gill-attachment        873757  16.82\n",
      "ring-type              215075   4.14\n",
      "gill-color                106   0.00\n",
      "cap-shape                  71   0.00\n",
      "habitat                    70   0.00\n",
      "stem-color                 59   0.00\n",
      "has-ring                   43   0.00\n",
      "cap-color                  25   0.00\n",
      "does-bruise-or-bleed       18   0.00\n",
      "cap-diameter               11   0.00\n",
      "stem-height                 1   0.00\n"
     ]
    }
   ],
   "source": [
    "def missing_values_table(dataframe, na_name=False):\n",
    "    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n",
    "\n",
    "    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n",
    "    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n",
    "    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n",
    "    print(missing_df, end=\"\\n\")\n",
    "\n",
    "    if na_name:\n",
    "        return na_columns\n",
    "\n",
    "\n",
    "missing_values_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb43ec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:20:09.979540Z",
     "iopub.status.busy": "2024-08-18T21:20:09.978767Z",
     "iopub.status.idle": "2024-08-18T21:20:10.878272Z",
     "shell.execute_reply": "2024-08-18T21:20:10.877097Z"
    },
    "papermill": {
     "duration": 0.914971,
     "end_time": "2024-08-18T21:20:10.880842",
     "exception": false,
     "start_time": "2024-08-18T21:20:09.965871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['veil-type', 'spore-print-color', 'stem-root', 'veil-color']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf0bbea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:20:10.905192Z",
     "iopub.status.busy": "2024-08-18T21:20:10.904684Z",
     "iopub.status.idle": "2024-08-18T21:20:15.086696Z",
     "shell.execute_reply": "2024-08-18T21:20:15.085258Z"
    },
    "papermill": {
     "duration": 4.197529,
     "end_time": "2024-08-18T21:20:15.089612",
     "exception": false,
     "start_time": "2024-08-18T21:20:10.892083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 5194909\n",
      "Variables: 19\n",
      "cat_cols: 14\n",
      "num_cols: 4\n",
      "cat_but_car: 10\n",
      "num_but_cat: 1\n"
     ]
    }
   ],
   "source": [
    "def grab_col_names(dataframe,cat_th=10,car_th=30):\n",
    "    cat_cols=[col for col in dataframe.columns if dataframe[col].dtypes=='object' and col!='dataset']\n",
    "    num_but_cat=[col for col in dataframe.columns if dataframe[col].dtypes!='O' and dataframe[col].nunique() < cat_th]\n",
    "    cat_but_car=[col for col in dataframe.columns if dataframe[col].dtypes=='O' and dataframe[col].nunique()>car_th and col!='dataset']\n",
    "    cat_cols=cat_cols+num_but_cat\n",
    "    num_cols=[col for col in dataframe.columns if dataframe[col].dtypes!='O']\n",
    "    num_cols=[col for col in num_cols if col not in num_but_cat]\n",
    "    print(f\"Observations: {dataframe.shape[0]}\")\n",
    "    print(f\"Variables: {dataframe.shape[1]}\")\n",
    "    print(f'cat_cols: {len(cat_cols)}')\n",
    "    print(f'num_cols: {len(num_cols)}')\n",
    "    print(f'cat_but_car: {len(cat_but_car)}')\n",
    "    print(f'num_but_cat: {len(num_but_cat)}')\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "\n",
    "cat_cols, num_cols, cat_but_car = grab_col_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcac8903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:20:15.116505Z",
     "iopub.status.busy": "2024-08-18T21:20:15.115591Z",
     "iopub.status.idle": "2024-08-18T21:20:19.300142Z",
     "shell.execute_reply": "2024-08-18T21:20:19.299046Z"
    },
    "papermill": {
     "duration": 4.200232,
     "end_time": "2024-08-18T21:20:19.302620",
     "exception": false,
     "start_time": "2024-08-18T21:20:15.102388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 5194909\n",
      "Variables: 19\n",
      "cat_cols: 14\n",
      "num_cols: 4\n",
      "cat_but_car: 10\n",
      "num_but_cat: 1\n",
      "['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-surface', 'stem-color', 'has-ring', 'ring-type', 'habitat', 'season']\n"
     ]
    }
   ],
   "source": [
    "cat_cols, num_cols, cat_but_car = grab_col_names(df)\n",
    "cat_cols = [col for col in cat_cols if col not in [\"class\",'dataset']]\n",
    "num_cols = [col for col in num_cols if col not in [\"id\"]]\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08d3e631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:20:19.326533Z",
     "iopub.status.busy": "2024-08-18T21:20:19.326151Z",
     "iopub.status.idle": "2024-08-18T21:20:22.707972Z",
     "shell.execute_reply": "2024-08-18T21:20:22.707097Z"
    },
    "papermill": {
     "duration": 3.396929,
     "end_time": "2024-08-18T21:20:22.710390",
     "exception": false,
     "start_time": "2024-08-18T21:20:19.313461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "df[num_cols] = numeric_imputer.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73995160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:20:22.735345Z",
     "iopub.status.busy": "2024-08-18T21:20:22.734946Z",
     "iopub.status.idle": "2024-08-18T21:20:51.504351Z",
     "shell.execute_reply": "2024-08-18T21:20:51.503429Z"
    },
    "papermill": {
     "duration": 28.785105,
     "end_time": "2024-08-18T21:20:51.507090",
     "exception": false,
     "start_time": "2024-08-18T21:20:22.721985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " for col in cat_cols:\n",
    "        df[col] = df[col].fillna('missing')\n",
    "        df.loc[df[col].value_counts(dropna=False)[df[col]].values < 100, col] = \"noise\"\n",
    "        df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3d28f32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:20:51.533165Z",
     "iopub.status.busy": "2024-08-18T21:20:51.532161Z",
     "iopub.status.idle": "2024-08-18T21:20:51.537543Z",
     "shell.execute_reply": "2024-08-18T21:20:51.536473Z"
    },
    "papermill": {
     "duration": 0.020668,
     "end_time": "2024-08-18T21:20:51.539837",
     "exception": false,
     "start_time": "2024-08-18T21:20:51.519169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def replace_non_alpha_with_nan(df):\n",
    " #   object_columns = [col for col in df.columns if df[col].dtype == 'object' and col!='dataset']\n",
    " #   alphabet_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "  #  def filter_alpha(value):\n",
    "  #      if isinstance(value, str):\n",
    "  #          return value if len(value) == 1 and value in alphabet_list else np.nan\n",
    "   #     return np.nan\n",
    "    #for col in object_columns:\n",
    "     #   df[col] = df[col].apply(filter_alpha)\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8413a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:20:51.564676Z",
     "iopub.status.busy": "2024-08-18T21:20:51.563891Z",
     "iopub.status.idle": "2024-08-18T21:20:51.568641Z",
     "shell.execute_reply": "2024-08-18T21:20:51.567548Z"
    },
    "papermill": {
     "duration": 0.019877,
     "end_time": "2024-08-18T21:20:51.571113",
     "exception": false,
     "start_time": "2024-08-18T21:20:51.551236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = replace_non_alpha_with_nan(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899af68f",
   "metadata": {
    "papermill": {
     "duration": 0.011305,
     "end_time": "2024-08-18T21:20:51.594516",
     "exception": false,
     "start_time": "2024-08-18T21:20:51.583211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modeling : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54afdeda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:20:51.619805Z",
     "iopub.status.busy": "2024-08-18T21:20:51.618868Z",
     "iopub.status.idle": "2024-08-18T21:20:53.999413Z",
     "shell.execute_reply": "2024-08-18T21:20:53.998240Z"
    },
    "papermill": {
     "duration": 2.395836,
     "end_time": "2024-08-18T21:20:54.002186",
     "exception": false,
     "start_time": "2024-08-18T21:20:51.606350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_processed = df[df['dataset'] == 'train'].drop(columns=['dataset'])\n",
    "test_processed = df[df['dataset'] == 'test'].drop(columns=['dataset'])\n",
    "\n",
    "\n",
    "\n",
    "X = train_processed.drop(columns=['class'])\n",
    "y = train_processed['class'] \n",
    "\n",
    "\n",
    "test_processed=test_processed.drop(columns=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da76441d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:20:54.026839Z",
     "iopub.status.busy": "2024-08-18T21:20:54.026455Z",
     "iopub.status.idle": "2024-08-18T21:20:54.747353Z",
     "shell.execute_reply": "2024-08-18T21:20:54.746378Z"
    },
    "papermill": {
     "duration": 0.736224,
     "end_time": "2024-08-18T21:20:54.749897",
     "exception": false,
     "start_time": "2024-08-18T21:20:54.013673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf71cb42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T21:20:54.775608Z",
     "iopub.status.busy": "2024-08-18T21:20:54.774552Z",
     "iopub.status.idle": "2024-08-18T22:37:56.598316Z",
     "shell.execute_reply": "2024-08-18T22:37:56.597118Z"
    },
    "papermill": {
     "duration": 4621.839329,
     "end_time": "2024-08-18T22:37:56.600823",
     "exception": false,
     "start_time": "2024-08-18T21:20:54.761494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:20:54,787] A new study created in memory with name: no-name-8e5f5a0d-4e9d-4d5d-b448-aae6652aa69f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.485063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.330793\n",
      "[100]\tvalid_0's binary_logloss: 0.184285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.184285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:21:39,076] Trial 0 finished with value: 0.9889517947050747 and parameters: {'learning_rate': 0.013386317965741973, 'num_leaves': 115, 'max_depth': 13, 'feature_fraction': 0.6976567346375632, 'bagging_fraction': 0.7422183008310783, 'bagging_freq': 1, 'min_data_in_leaf': 94, 'lambda_l1': 7.052834714933471e-05, 'lambda_l2': 2.026833622530663}. Best is trial 0 with value: 0.9889517947050747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.277583\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.17927\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.17927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:22:10,536] Trial 1 finished with value: 0.9708432611401756 and parameters: {'learning_rate': 0.040857009568322965, 'num_leaves': 35, 'max_depth': 5, 'feature_fraction': 0.7722633781647056, 'bagging_fraction': 0.6887938440382385, 'bagging_freq': 3, 'min_data_in_leaf': 54, 'lambda_l1': 5.825444740773138, 'lambda_l2': 2.0403510856616137e-08}. Best is trial 0 with value: 0.9889517947050747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0956868\n",
      "[100]\tvalid_0's binary_logloss: 0.049388\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.049388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:23:01,629] Trial 2 finished with value: 0.989994481779177 and parameters: {'learning_rate': 0.050809253444315985, 'num_leaves': 109, 'max_depth': 9, 'feature_fraction': 0.8943603800788495, 'bagging_fraction': 0.9632662106524463, 'bagging_freq': 6, 'min_data_in_leaf': 93, 'lambda_l1': 0.0013487232242915443, 'lambda_l2': 0.004810044383151175}. Best is trial 2 with value: 0.989994481779177.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.190018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0673752\n",
      "[100]\tvalid_0's binary_logloss: 0.0422141\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0422141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:23:45,490] Trial 3 finished with value: 0.9906446907443609 and parameters: {'learning_rate': 0.09480478293612615, 'num_leaves': 42, 'max_depth': 9, 'feature_fraction': 0.8282750118929109, 'bagging_fraction': 0.9355435868482296, 'bagging_freq': 7, 'min_data_in_leaf': 49, 'lambda_l1': 2.4096143906495228e-05, 'lambda_l2': 4.368466958992483}. Best is trial 3 with value: 0.9906446907443609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.167712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.039455\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's binary_logloss: 0.0381799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:24:23,222] Trial 4 finished with value: 0.9916296289958977 and parameters: {'learning_rate': 0.1553803069780135, 'num_leaves': 117, 'max_depth': 11, 'feature_fraction': 0.7462800925061368, 'bagging_fraction': 0.7856262923631068, 'bagging_freq': 4, 'min_data_in_leaf': 35, 'lambda_l1': 3.100906859624162e-06, 'lambda_l2': 4.9054103884632005e-06}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.449006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0500803\n",
      "[100]\tvalid_0's binary_logloss: 0.0390246\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0390246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:25:12,194] Trial 5 finished with value: 0.9913825923660334 and parameters: {'learning_rate': 0.10432657982810087, 'num_leaves': 59, 'max_depth': 20, 'feature_fraction': 0.7076743439013428, 'bagging_fraction': 0.8003634147647377, 'bagging_freq': 4, 'min_data_in_leaf': 54, 'lambda_l1': 1.5431703539065717e-08, 'lambda_l2': 0.0004088929820122474}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.468562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.141344\n",
      "[100]\tvalid_0's binary_logloss: 0.0593586\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0593586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:26:04,939] Trial 6 finished with value: 0.9904361533295405 and parameters: {'learning_rate': 0.033408457515156816, 'num_leaves': 117, 'max_depth': 18, 'feature_fraction': 0.7274904771481969, 'bagging_fraction': 0.6587041467587748, 'bagging_freq': 7, 'min_data_in_leaf': 96, 'lambda_l1': 1.3973573898774664e-05, 'lambda_l2': 0.00405703997337142}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.182910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.142938\n",
      "[100]\tvalid_0's binary_logloss: 0.0626242\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0626242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:26:42,681] Trial 7 finished with value: 0.989433034893122 and parameters: {'learning_rate': 0.03968470663289157, 'num_leaves': 56, 'max_depth': 20, 'feature_fraction': 0.7388257531624193, 'bagging_fraction': 0.7982866135780973, 'bagging_freq': 1, 'min_data_in_leaf': 99, 'lambda_l1': 3.7098401538669226e-07, 'lambda_l2': 1.0083115135760773e-08}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.172694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.137137\n",
      "[100]\tvalid_0's binary_logloss: 0.0609744\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0609744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:27:33,767] Trial 8 finished with value: 0.9890041964144398 and parameters: {'learning_rate': 0.038313098413549726, 'num_leaves': 64, 'max_depth': 13, 'feature_fraction': 0.8806642383574428, 'bagging_fraction': 0.9191774645664971, 'bagging_freq': 6, 'min_data_in_leaf': 54, 'lambda_l1': 0.00037325124876898215, 'lambda_l2': 3.531739856902369e-08}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.189737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.274749\n",
      "[100]\tvalid_0's binary_logloss: 0.1369\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.1369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:28:26,875] Trial 9 finished with value: 0.9886534257884854 and parameters: {'learning_rate': 0.017415117996539557, 'num_leaves': 99, 'max_depth': 0, 'feature_fraction': 0.7496806445841192, 'bagging_fraction': 0.913147427905962, 'bagging_freq': 2, 'min_data_in_leaf': 75, 'lambda_l1': 5.578010697954164, 'lambda_l2': 0.18879398627082136}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.457482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.265883\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.162053\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.162053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:28:47,791] Trial 10 finished with value: 0.9670318388508412 and parameters: {'learning_rate': 0.1600900731464712, 'num_leaves': 147, 'max_depth': 3, 'feature_fraction': 0.6074980550530701, 'bagging_fraction': 0.6035901212289538, 'bagging_freq': 4, 'min_data_in_leaf': 17, 'lambda_l1': 0.039230396929351305, 'lambda_l2': 3.2074812833112683e-06}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.041091\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's binary_logloss: 0.0389123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:29:28,731] Trial 11 finished with value: 0.9914050502414756 and parameters: {'learning_rate': 0.14377026096090018, 'num_leaves': 70, 'max_depth': 16, 'feature_fraction': 0.9920111317478847, 'bagging_fraction': 0.831143018165334, 'bagging_freq': 4, 'min_data_in_leaf': 31, 'lambda_l1': 1.3347350945388216e-08, 'lambda_l2': 1.9961513942471013e-05}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.312517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0396368\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's binary_logloss: 0.03885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:30:04,483] Trial 12 finished with value: 0.991387939479234 and parameters: {'learning_rate': 0.16874697831085475, 'num_leaves': 82, 'max_depth': 15, 'feature_fraction': 0.9949912284834818, 'bagging_fraction': 0.8423659800349513, 'bagging_freq': 5, 'min_data_in_leaf': 27, 'lambda_l1': 1.2335765292580764e-08, 'lambda_l2': 7.456482304156161e-06}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.179121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0447372\n",
      "[100]\tvalid_0's binary_logloss: 0.0385485\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0385485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:30:58,805] Trial 13 finished with value: 0.9914136056225965 and parameters: {'learning_rate': 0.09162176458666732, 'num_leaves': 131, 'max_depth': 16, 'feature_fraction': 0.9737528972425897, 'bagging_fraction': 0.848790506090192, 'bagging_freq': 3, 'min_data_in_leaf': 33, 'lambda_l1': 7.24264736073072e-07, 'lambda_l2': 6.119562715373321e-06}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.463120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0544344\n",
      "[100]\tvalid_0's binary_logloss: 0.0388988\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0388988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:31:54,761] Trial 14 finished with value: 0.9915729495959721 and parameters: {'learning_rate': 0.07586275799768884, 'num_leaves': 141, 'max_depth': 11, 'feature_fraction': 0.6515342476849614, 'bagging_fraction': 0.8747577080571138, 'bagging_freq': 3, 'min_data_in_leaf': 36, 'lambda_l1': 2.1051944600888466e-06, 'lambda_l2': 1.3794534671193814e-06}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.448498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.17517\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.0894346\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0894346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:32:31,760] Trial 15 finished with value: 0.9869049197719135 and parameters: {'learning_rate': 0.06142036401766054, 'num_leaves': 148, 'max_depth': 6, 'feature_fraction': 0.6383107239512509, 'bagging_fraction': 0.7493049261372757, 'bagging_freq': 3, 'min_data_in_leaf': 41, 'lambda_l1': 2.2282351525936014e-07, 'lambda_l2': 5.910860921321765e-07}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.441884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.066964\n",
      "[100]\tvalid_0's binary_logloss: 0.0407595\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0407595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:33:31,108] Trial 16 finished with value: 0.991368689871712 and parameters: {'learning_rate': 0.06305716296492883, 'num_leaves': 132, 'max_depth': 11, 'feature_fraction': 0.6652626562671385, 'bagging_fraction': 0.9960787891359325, 'bagging_freq': 2, 'min_data_in_leaf': 13, 'lambda_l1': 3.5284861250222792e-06, 'lambda_l2': 2.4789400138106185e-07}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.169513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.038851\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's binary_logloss: 0.0382633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:34:07,202] Trial 17 finished with value: 0.9915879215129336 and parameters: {'learning_rate': 0.19873179099821486, 'num_leaves': 92, 'max_depth': 11, 'feature_fraction': 0.8135698440870944, 'bagging_fraction': 0.8903897430572529, 'bagging_freq': 5, 'min_data_in_leaf': 70, 'lambda_l1': 0.0016675182916897964, 'lambda_l2': 8.743206845895815e-05}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.172731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.0780229\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.0456114\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0456114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:34:43,074] Trial 18 finished with value: 0.9903591548994529 and parameters: {'learning_rate': 0.1296341528559875, 'num_leaves': 90, 'max_depth': 6, 'feature_fraction': 0.8083844669494338, 'bagging_fraction': 0.7509027955815446, 'bagging_freq': 5, 'min_data_in_leaf': 67, 'lambda_l1': 0.004954248425448501, 'lambda_l2': 9.604687436203848e-05}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.166539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.341423\n",
      "[100]\tvalid_0's binary_logloss: 0.214029\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.214029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:35:21,457] Trial 19 finished with value: 0.9703983813218919 and parameters: {'learning_rate': 0.024154680420861985, 'num_leaves': 22, 'max_depth': 8, 'feature_fraction': 0.8437559281649376, 'bagging_fraction': 0.8872826860801057, 'bagging_freq': 5, 'min_data_in_leaf': 68, 'lambda_l1': 0.10264956457563733, 'lambda_l2': 0.0010330576511717866}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.173865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0392034\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's binary_logloss: 0.0386861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:35:52,465] Trial 20 finished with value: 0.9914210915810772 and parameters: {'learning_rate': 0.19260700948944856, 'num_leaves': 81, 'max_depth': 13, 'feature_fraction': 0.9308355042700505, 'bagging_fraction': 0.7994405275676493, 'bagging_freq': 6, 'min_data_in_leaf': 85, 'lambda_l1': 0.0201657967207376, 'lambda_l2': 5.6233839303882364e-05}. Best is trial 4 with value: 0.9916296289958977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0421643\n",
      "[100]\tvalid_0's binary_logloss: 0.0377319\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0377319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:36:46,044] Trial 21 finished with value: 0.991796458927754 and parameters: {'learning_rate': 0.11451615451841457, 'num_leaves': 132, 'max_depth': 11, 'feature_fraction': 0.7811073415504477, 'bagging_fraction': 0.8790056941105341, 'bagging_freq': 3, 'min_data_in_leaf': 42, 'lambda_l1': 0.00020631909907595672, 'lambda_l2': 5.471978213751572e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.161832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0416497\n",
      "[100]\tvalid_0's binary_logloss: 0.0378486\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0378486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:37:37,513] Trial 22 finished with value: 0.9917536820221499 and parameters: {'learning_rate': 0.11901625398108974, 'num_leaves': 125, 'max_depth': 11, 'feature_fraction': 0.7849701628577789, 'bagging_fraction': 0.8738746265937565, 'bagging_freq': 5, 'min_data_in_leaf': 45, 'lambda_l1': 0.00032469385641344513, 'lambda_l2': 1.3494937057481397e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.166235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0398472\n",
      "[100]\tvalid_0's binary_logloss: 0.0377033\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0377033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:38:29,480] Trial 23 finished with value: 0.9917526125995098 and parameters: {'learning_rate': 0.12371302175996551, 'num_leaves': 128, 'max_depth': 14, 'feature_fraction': 0.7766449841489244, 'bagging_fraction': 0.7738179408340236, 'bagging_freq': 2, 'min_data_in_leaf': 45, 'lambda_l1': 0.00018353514094450585, 'lambda_l2': 1.1158622940772214e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.170616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0409326\n",
      "[100]\tvalid_0's binary_logloss: 0.0377468\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0377468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:39:21,513] Trial 24 finished with value: 0.9917590291353504 and parameters: {'learning_rate': 0.11137390572807049, 'num_leaves': 131, 'max_depth': 14, 'feature_fraction': 0.7757500108076115, 'bagging_fraction': 0.706881452034784, 'bagging_freq': 2, 'min_data_in_leaf': 46, 'lambda_l1': 0.00010793763775063623, 'lambda_l2': 1.1835591140830323e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.173937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0519307\n",
      "[100]\tvalid_0's binary_logloss: 0.0387234\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0387234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:40:14,624] Trial 25 finished with value: 0.9914510354150001 and parameters: {'learning_rate': 0.07743289715936229, 'num_leaves': 104, 'max_depth': 17, 'feature_fraction': 0.8461502318265365, 'bagging_fraction': 0.6962293894049535, 'bagging_freq': 2, 'min_data_in_leaf': 24, 'lambda_l1': 0.30338013021459553, 'lambda_l2': 1.0513383338750635e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0527487\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.0390135\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0390135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:40:51,604] Trial 26 finished with value: 0.9914692155998819 and parameters: {'learning_rate': 0.11383523711018464, 'num_leaves': 126, 'max_depth': 8, 'feature_fraction': 0.7768693761553133, 'bagging_fraction': 0.9569808757870303, 'bagging_freq': 1, 'min_data_in_leaf': 61, 'lambda_l1': 0.00035271612111390687, 'lambda_l2': 4.260914774758176e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.173037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0493567\n",
      "[100]\tvalid_0's binary_logloss: 0.0387222\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0387222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:41:41,854] Trial 27 finished with value: 0.991429646962198 and parameters: {'learning_rate': 0.08086861709109676, 'num_leaves': 139, 'max_depth': 12, 'feature_fraction': 0.8779920224666833, 'bagging_fraction': 0.6069226881136396, 'bagging_freq': 3, 'min_data_in_leaf': 43, 'lambda_l1': 4.511309438666594e-05, 'lambda_l2': 6.245027899699193e-08}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.391819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0680713\n",
      "[100]\tvalid_0's binary_logloss: 0.0400962\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0400962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:42:36,088] Trial 28 finished with value: 0.9913932865924345 and parameters: {'learning_rate': 0.05874348489246806, 'num_leaves': 122, 'max_depth': 18, 'feature_fraction': 0.6911879853620934, 'bagging_fraction': 0.6966580654921433, 'bagging_freq': 2, 'min_data_in_leaf': 60, 'lambda_l1': 0.005764467597400502, 'lambda_l2': 1.003901454825542e-06}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.164610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.335757\n",
      "[100]\tvalid_0's binary_logloss: 0.187945\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.187945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:43:16,321] Trial 29 finished with value: 0.9885935381206394 and parameters: {'learning_rate': 0.012956368540286855, 'num_leaves': 111, 'max_depth': 14, 'feature_fraction': 0.7878286036642941, 'bagging_fraction': 0.8288312762984271, 'bagging_freq': 1, 'min_data_in_leaf': 21, 'lambda_l1': 6.216975219119723e-05, 'lambda_l2': 0.487138832663383}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.410668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.241577\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.129749\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.129749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:44:04,800] Trial 30 finished with value: 0.9860782560711123 and parameters: {'learning_rate': 0.02840302743522433, 'num_leaves': 138, 'max_depth': 7, 'feature_fraction': 0.6964309230059426, 'bagging_fraction': 0.8611369484214064, 'bagging_freq': 3, 'min_data_in_leaf': 47, 'lambda_l1': 0.0001611518126962215, 'lambda_l2': 1.0913552923218355e-08}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.162513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0401927\n",
      "[100]\tvalid_0's binary_logloss: 0.0377431\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0377431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:44:57,698] Trial 31 finished with value: 0.991785764701353 and parameters: {'learning_rate': 0.12063816739619536, 'num_leaves': 126, 'max_depth': 14, 'feature_fraction': 0.7603886951682651, 'bagging_fraction': 0.7682368245107074, 'bagging_freq': 2, 'min_data_in_leaf': 41, 'lambda_l1': 0.0009400973718761118, 'lambda_l2': 1.2556768257468416e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.165338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.380339\n",
      "[100]\tvalid_0's binary_logloss: 0.231815\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.231815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:45:48,159] Trial 32 finished with value: 0.9885614554414363 and parameters: {'learning_rate': 0.010361014569700247, 'num_leaves': 121, 'max_depth': 14, 'feature_fraction': 0.7560856007660066, 'bagging_fraction': 0.7181182511684384, 'bagging_freq': 2, 'min_data_in_leaf': 37, 'lambda_l1': 0.0016797561631925124, 'lambda_l2': 1.9156170740107624e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.175257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.044633\n",
      "[100]\tvalid_0's binary_logloss: 0.0382873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0382873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:46:28,024] Trial 33 finished with value: 0.991623212460057 and parameters: {'learning_rate': 0.11402618454348316, 'num_leaves': 103, 'max_depth': 10, 'feature_fraction': 0.7996072639488564, 'bagging_fraction': 0.6418802185219914, 'bagging_freq': 1, 'min_data_in_leaf': 40, 'lambda_l1': 8.585683694226897e-06, 'lambda_l2': 2.255649219780122e-08}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.420497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0448133\n",
      "[100]\tvalid_0's binary_logloss: 0.0378561\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0378561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:47:24,275] Trial 34 finished with value: 0.9917034191580649 and parameters: {'learning_rate': 0.09198583168994912, 'num_leaves': 150, 'max_depth': 12, 'feature_fraction': 0.7158413839456254, 'bagging_fraction': 0.7304969206126973, 'bagging_freq': 3, 'min_data_in_leaf': 50, 'lambda_l1': 0.00045549930283486477, 'lambda_l2': 1.2844448725868262e-06}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.171298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.101421\n",
      "[100]\tvalid_0's binary_logloss: 0.0513718\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0513718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:48:13,750] Trial 35 finished with value: 0.9901388538355912 and parameters: {'learning_rate': 0.04899556530008793, 'num_leaves': 134, 'max_depth': 9, 'feature_fraction': 0.8281800013380465, 'bagging_fraction': 0.7669146523146151, 'bagging_freq': 4, 'min_data_in_leaf': 60, 'lambda_l1': 0.006293668576108847, 'lambda_l2': 4.510568444430667e-08}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0389132\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.0378186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:48:59,983] Trial 36 finished with value: 0.9917408489504687 and parameters: {'learning_rate': 0.1468068954008819, 'num_leaves': 112, 'max_depth': 15, 'feature_fraction': 0.7625744048300118, 'bagging_fraction': 0.9061386120609265, 'bagging_freq': 2, 'min_data_in_leaf': 50, 'lambda_l1': 0.00108472059940612, 'lambda_l2': 3.411484367424536e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0460211\n",
      "[100]\tvalid_0's binary_logloss: 0.0387453\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0387453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:49:50,911] Trial 37 finished with value: 0.9914007725509152 and parameters: {'learning_rate': 0.10013864472236875, 'num_leaves': 122, 'max_depth': 10, 'feature_fraction': 0.8567822262566455, 'bagging_fraction': 0.8166533374153284, 'bagging_freq': 4, 'min_data_in_leaf': 27, 'lambda_l1': 5.907147856640209e-05, 'lambda_l2': 1.516195767574998e-05}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.404819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.287529\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.179873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.179873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:50:13,355] Trial 38 finished with value: 0.9627092325395366 and parameters: {'learning_rate': 0.1306239032516927, 'num_leaves': 142, 'max_depth': 3, 'feature_fraction': 0.730135221749465, 'bagging_fraction': 0.6687723163168381, 'bagging_freq': 6, 'min_data_in_leaf': 56, 'lambda_l1': 1.1028397562282518e-05, 'lambda_l2': 1.8703556659641479e-06}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.165566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0579662\n",
      "[100]\tvalid_0's binary_logloss: 0.0394442\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0394442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:51:09,583] Trial 39 finished with value: 0.9913601344905912 and parameters: {'learning_rate': 0.06923625723784776, 'num_leaves': 116, 'max_depth': 12, 'feature_fraction': 0.790860412019543, 'bagging_fraction': 0.9404133443814706, 'bagging_freq': 3, 'min_data_in_leaf': 30, 'lambda_l1': 9.864031101115293e-05, 'lambda_l2': 0.03535165278462992}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.542388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.046922\n",
      "[100]\tvalid_0's binary_logloss: 0.0380625\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0380625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:51:56,900] Trial 40 finished with value: 0.9916542257166201 and parameters: {'learning_rate': 0.08746978565790585, 'num_leaves': 108, 'max_depth': 18, 'feature_fraction': 0.679992094058639, 'bagging_fraction': 0.7124617238917318, 'bagging_freq': 1, 'min_data_in_leaf': 39, 'lambda_l1': 0.000823869840374041, 'lambda_l2': 7.939172624256722e-08}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0404247\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's binary_logloss: 0.0377571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:52:48,514] Trial 41 finished with value: 0.9917633068259109 and parameters: {'learning_rate': 0.11707461160520713, 'num_leaves': 129, 'max_depth': 14, 'feature_fraction': 0.7744114618916991, 'bagging_fraction': 0.7738453466344166, 'bagging_freq': 2, 'min_data_in_leaf': 46, 'lambda_l1': 0.0001527041091056897, 'lambda_l2': 1.5508436290131307e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.171723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0418047\n",
      "[100]\tvalid_0's binary_logloss: 0.0379366\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0379366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:53:42,886] Trial 42 finished with value: 0.9916585034071805 and parameters: {'learning_rate': 0.10880471175443357, 'num_leaves': 126, 'max_depth': 13, 'feature_fraction': 0.8248197068336242, 'bagging_fraction': 0.7630755240622412, 'bagging_freq': 2, 'min_data_in_leaf': 46, 'lambda_l1': 0.003126155537221813, 'lambda_l2': 2.4898711925013266e-08}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.173045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.038297\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.0378129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:54:24,514] Trial 43 finished with value: 0.9917419183731088 and parameters: {'learning_rate': 0.16427133077628092, 'num_leaves': 135, 'max_depth': 15, 'feature_fraction': 0.7408030152680292, 'bagging_fraction': 0.7275333906960338, 'bagging_freq': 2, 'min_data_in_leaf': 53, 'lambda_l1': 2.6684194444033178e-05, 'lambda_l2': 2.1255116551718876e-07}. Best is trial 21 with value: 0.991796458927754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.166769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0387299\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's binary_logloss: 0.037701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:55:02,118] Trial 44 finished with value: 0.9918146391126359 and parameters: {'learning_rate': 0.13578362027080743, 'num_leaves': 143, 'max_depth': 16, 'feature_fraction': 0.7685593886568047, 'bagging_fraction': 0.7892109091602152, 'bagging_freq': 1, 'min_data_in_leaf': 43, 'lambda_l1': 0.00017522619401158404, 'lambda_l2': 3.1466597004644686e-06}. Best is trial 44 with value: 0.9918146391126359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.446665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0386902\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's binary_logloss: 0.0377114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:55:41,879] Trial 45 finished with value: 0.9917707927843915 and parameters: {'learning_rate': 0.13634278396048877, 'num_leaves': 143, 'max_depth': 19, 'feature_fraction': 0.7163348598671572, 'bagging_fraction': 0.7786354329780804, 'bagging_freq': 1, 'min_data_in_leaf': 35, 'lambda_l1': 0.013636215513159187, 'lambda_l2': 3.020266131206434e-06}. Best is trial 44 with value: 0.9918146391126359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.459735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0385223\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's binary_logloss: 0.0377744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:56:18,393] Trial 46 finished with value: 0.9917558208674301 and parameters: {'learning_rate': 0.1403578970417935, 'num_leaves': 144, 'max_depth': 19, 'feature_fraction': 0.7165050899230978, 'bagging_fraction': 0.7874283921962683, 'bagging_freq': 1, 'min_data_in_leaf': 32, 'lambda_l1': 0.023048027805523456, 'lambda_l2': 1.8746682484215494e-05}. Best is trial 44 with value: 0.9918146391126359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.179901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0380186\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's binary_logloss: 0.0376176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:56:56,573] Trial 47 finished with value: 0.9918424441012786 and parameters: {'learning_rate': 0.1814739648157738, 'num_leaves': 142, 'max_depth': 20, 'feature_fraction': 0.75347339128726, 'bagging_fraction': 0.815946404756599, 'bagging_freq': 1, 'min_data_in_leaf': 36, 'lambda_l1': 0.8784095735335989, 'lambda_l2': 3.146243882221641e-06}. Best is trial 47 with value: 0.9918424441012786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.617611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0381621\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's binary_logloss: 0.0380184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:57:27,354] Trial 48 finished with value: 0.9916510174486998 and parameters: {'learning_rate': 0.17857454286600938, 'num_leaves': 146, 'max_depth': 20, 'feature_fraction': 0.7538667039928398, 'bagging_fraction': 0.8135137073696709, 'bagging_freq': 1, 'min_data_in_leaf': 19, 'lambda_l1': 0.5589184460404943, 'lambda_l2': 4.778395955080237e-06}. Best is trial 47 with value: 0.9918424441012786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.417386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0384036\n",
      "[100]\tvalid_0's binary_logloss: 0.037353\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.037353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:58:16,183] Trial 49 finished with value: 0.9918991235012041 and parameters: {'learning_rate': 0.1555054221116813, 'num_leaves': 140, 'max_depth': 17, 'feature_fraction': 0.7265736786119602, 'bagging_fraction': 0.8463822693922969, 'bagging_freq': 1, 'min_data_in_leaf': 35, 'lambda_l1': 2.586829710646719, 'lambda_l2': 0.000408811787072078}. Best is trial 49 with value: 0.9918991235012041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.423886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0383687\n",
      "[100]\tvalid_0's binary_logloss: 0.0373944\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0373944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:59:04,874] Trial 50 finished with value: 0.9918766656257619 and parameters: {'learning_rate': 0.17344036116035214, 'num_leaves': 150, 'max_depth': 17, 'feature_fraction': 0.7277147156555925, 'bagging_fraction': 0.8478004965159378, 'bagging_freq': 1, 'min_data_in_leaf': 29, 'lambda_l1': 9.971197790959824, 'lambda_l2': 0.0024326096993645217}. Best is trial 49 with value: 0.9918991235012041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.163383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0383894\n",
      "[100]\tvalid_0's binary_logloss: 0.0372542\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0372542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 21:59:50,310] Trial 51 finished with value: 0.9919322756030474 and parameters: {'learning_rate': 0.15796144862743075, 'num_leaves': 150, 'max_depth': 17, 'feature_fraction': 0.7445934144548301, 'bagging_fraction': 0.8506538777216452, 'bagging_freq': 1, 'min_data_in_leaf': 28, 'lambda_l1': 6.71767912014228, 'lambda_l2': 0.0024911999857609416}. Best is trial 51 with value: 0.9919322756030474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.440986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0382353\n",
      "[100]\tvalid_0's binary_logloss: 0.0372827\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0372827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:00:37,894] Trial 52 finished with value: 0.9919215813766463 and parameters: {'learning_rate': 0.1733037235118545, 'num_leaves': 150, 'max_depth': 16, 'feature_fraction': 0.7337787294747202, 'bagging_fraction': 0.857824836947947, 'bagging_freq': 1, 'min_data_in_leaf': 27, 'lambda_l1': 9.967523107441302, 'lambda_l2': 0.0043031734616854585}. Best is trial 51 with value: 0.9919322756030474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.615108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0384683\n",
      "[100]\tvalid_0's binary_logloss: 0.03749\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.03749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:01:26,205] Trial 53 finished with value: 0.9918745267804817 and parameters: {'learning_rate': 0.1785753097526948, 'num_leaves': 149, 'max_depth': 17, 'feature_fraction': 0.7315894802174002, 'bagging_fraction': 0.8517033052644987, 'bagging_freq': 1, 'min_data_in_leaf': 14, 'lambda_l1': 9.988114012886784, 'lambda_l2': 0.0028692100876505583}. Best is trial 51 with value: 0.9919322756030474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.166445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0380911\n",
      "[100]\tvalid_0's binary_logloss: 0.0373115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0373115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:02:12,494] Trial 54 finished with value: 0.9919461780973688 and parameters: {'learning_rate': 0.1832911138785497, 'num_leaves': 150, 'max_depth': 17, 'feature_fraction': 0.7370956182667594, 'bagging_fraction': 0.8533198320565855, 'bagging_freq': 1, 'min_data_in_leaf': 11, 'lambda_l1': 7.6592841735983415, 'lambda_l2': 0.005251526885843222}. Best is trial 54 with value: 0.9919461780973688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.674502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0384024\n",
      "[100]\tvalid_0's binary_logloss: 0.0373329\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0373329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:03:02,347] Trial 55 finished with value: 0.9919108871502453 and parameters: {'learning_rate': 0.16581984343823214, 'num_leaves': 150, 'max_depth': 17, 'feature_fraction': 0.6726817430498189, 'bagging_fraction': 0.8517045277946935, 'bagging_freq': 1, 'min_data_in_leaf': 11, 'lambda_l1': 7.903706644201828, 'lambda_l2': 0.008939216709440546}. Best is trial 54 with value: 0.9919461780973688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.454203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0383591\n",
      "[100]\tvalid_0's binary_logloss: 0.0372951\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's binary_logloss: 0.0372896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:03:50,142] Trial 56 finished with value: 0.9919622194369704 and parameters: {'learning_rate': 0.15320309804987312, 'num_leaves': 150, 'max_depth': 17, 'feature_fraction': 0.6394413269267387, 'bagging_fraction': 0.8338558100722285, 'bagging_freq': 1, 'min_data_in_leaf': 16, 'lambda_l1': 2.7380183994139493, 'lambda_l2': 0.010984455977466842}. Best is trial 56 with value: 0.9919622194369704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.436505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0382618\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's binary_logloss: 0.0372854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:04:36,864] Trial 57 finished with value: 0.9919664971275308 and parameters: {'learning_rate': 0.160771138635136, 'num_leaves': 137, 'max_depth': 19, 'feature_fraction': 0.62376834637681, 'bagging_fraction': 0.8618208801970265, 'bagging_freq': 1, 'min_data_in_leaf': 10, 'lambda_l1': 2.3954396419099337, 'lambda_l2': 0.0203916733761257}. Best is trial 57 with value: 0.9919664971275308.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.459455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0384111\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's binary_logloss: 0.037311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:05:24,010] Trial 58 finished with value: 0.9919675665501709 and parameters: {'learning_rate': 0.1570089046776225, 'num_leaves': 136, 'max_depth': 19, 'feature_fraction': 0.622981192126568, 'bagging_fraction': 0.8970254429615686, 'bagging_freq': 1, 'min_data_in_leaf': 10, 'lambda_l1': 2.6912461632162645, 'lambda_l2': 0.015406264409918633}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.447365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0443602\n",
      "[100]\tvalid_0's binary_logloss: 0.0387046\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0387046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:06:02,444] Trial 59 finished with value: 0.9915686719054118 and parameters: {'learning_rate': 0.15096968205725256, 'num_leaves': 49, 'max_depth': 19, 'feature_fraction': 0.6061304073210563, 'bagging_fraction': 0.8983239260744362, 'bagging_freq': 1, 'min_data_in_leaf': 10, 'lambda_l1': 2.736194535740059, 'lambda_l2': 0.01516473098355955}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.442281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0379876\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.0375136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:06:39,816] Trial 60 finished with value: 0.9918991235012041 and parameters: {'learning_rate': 0.19554967361379413, 'num_leaves': 135, 'max_depth': 19, 'feature_fraction': 0.6227134017714613, 'bagging_fraction': 0.9211739876236792, 'bagging_freq': 1, 'min_data_in_leaf': 17, 'lambda_l1': 2.7112727317211704, 'lambda_l2': 0.06421482202047336}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.499952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0382742\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's binary_logloss: 0.0375458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:07:21,403] Trial 61 finished with value: 0.9918488606371192 and parameters: {'learning_rate': 0.15413938096685784, 'num_leaves': 146, 'max_depth': 18, 'feature_fraction': 0.6488513053592538, 'bagging_fraction': 0.8668567911198459, 'bagging_freq': 1, 'min_data_in_leaf': 10, 'lambda_l1': 1.2454519766811394, 'lambda_l2': 0.01136323708854767}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.447385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0383524\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.0380507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:07:52,647] Trial 62 finished with value: 0.9917301547240676 and parameters: {'learning_rate': 0.16319469178013424, 'num_leaves': 137, 'max_depth': 16, 'feature_fraction': 0.6258692135962345, 'bagging_fraction': 0.8323045238152696, 'bagging_freq': 1, 'min_data_in_leaf': 14, 'lambda_l1': 0.15114287048253908, 'lambda_l2': 0.0009649618702015918}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.459879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0379027\n",
      "[100]\tvalid_0's binary_logloss: 0.03729\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's binary_logloss: 0.037281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:08:42,210] Trial 63 finished with value: 0.9919525946332094 and parameters: {'learning_rate': 0.1967176425470407, 'num_leaves': 150, 'max_depth': 16, 'feature_fraction': 0.6673085427378782, 'bagging_fraction': 0.8869631153933407, 'bagging_freq': 1, 'min_data_in_leaf': 23, 'lambda_l1': 5.349689731909263, 'lambda_l2': 0.007152545962726325}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.437161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0390709\n",
      "[100]\tvalid_0's binary_logloss: 0.0377117\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0377117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:09:23,942] Trial 64 finished with value: 0.9918135696899958 and parameters: {'learning_rate': 0.1978297768815702, 'num_leaves': 74, 'max_depth': 16, 'feature_fraction': 0.6604564686139879, 'bagging_fraction': 0.884050320602707, 'bagging_freq': 1, 'min_data_in_leaf': 23, 'lambda_l1': 4.206622451915672, 'lambda_l2': 0.042482614358058904}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.473786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0384448\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.0373437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:10:19,920] Trial 65 finished with value: 0.9919151648408058 and parameters: {'learning_rate': 0.14556571626882925, 'num_leaves': 146, 'max_depth': 18, 'feature_fraction': 0.632142116943195, 'bagging_fraction': 0.9255228344878752, 'bagging_freq': 2, 'min_data_in_leaf': 17, 'lambda_l1': 1.3887331447236189, 'lambda_l2': 0.11831514602810807}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.496206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0381417\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's binary_logloss: 0.037902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:10:52,198] Trial 66 finished with value: 0.9917686539391114 and parameters: {'learning_rate': 0.18505240248574825, 'num_leaves': 138, 'max_depth': 20, 'feature_fraction': 0.6458918953236916, 'bagging_fraction': 0.8967772116475797, 'bagging_freq': 1, 'min_data_in_leaf': 23, 'lambda_l1': 0.4347291963401575, 'lambda_l2': 0.0013280277904600744}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.454488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.236966\n",
      "[100]\tvalid_0's binary_logloss: 0.109074\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.109074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:11:38,928] Trial 67 finished with value: 0.9904639583181831 and parameters: {'learning_rate': 0.02081791090848365, 'num_leaves': 145, 'max_depth': 15, 'feature_fraction': 0.6148316135768795, 'bagging_fraction': 0.8689407412624447, 'bagging_freq': 1, 'min_data_in_leaf': 20, 'lambda_l1': 0.11751445695625042, 'lambda_l2': 1.4444673865214241}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.443880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0425755\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's binary_logloss: 0.0376583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:12:35,752] Trial 68 finished with value: 0.9918210556484764 and parameters: {'learning_rate': 0.10145150224726246, 'num_leaves': 140, 'max_depth': 19, 'feature_fraction': 0.6012868425067373, 'bagging_fraction': 0.8337400983014643, 'bagging_freq': 7, 'min_data_in_leaf': 16, 'lambda_l1': 0.2605215729225954, 'lambda_l2': 0.00019196984664362137}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.482108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0440514\n",
      "[100]\tvalid_0's binary_logloss: 0.0388221\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0388221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:13:22,650] Trial 69 finished with value: 0.9914916734753242 and parameters: {'learning_rate': 0.1996550239766207, 'num_leaves': 33, 'max_depth': -1, 'feature_fraction': 0.6888592493165152, 'bagging_fraction': 0.9409788588037151, 'bagging_freq': 2, 'min_data_in_leaf': 26, 'lambda_l1': 4.436608497425244, 'lambda_l2': 0.005051760232679361}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.453045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0392094\n",
      "[100]\tvalid_0's binary_logloss: 0.0373077\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0373077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:14:09,679] Trial 70 finished with value: 0.9919440392520886 and parameters: {'learning_rate': 0.1287387737801115, 'num_leaves': 136, 'max_depth': 18, 'feature_fraction': 0.6582362267277032, 'bagging_fraction': 0.8604451518869471, 'bagging_freq': 1, 'min_data_in_leaf': 13, 'lambda_l1': 1.7379264934206968, 'lambda_l2': 0.020747959170650015}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.492847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0393104\n",
      "[100]\tvalid_0's binary_logloss: 0.0373418\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0373418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:14:57,072] Trial 71 finished with value: 0.9919429698294485 and parameters: {'learning_rate': 0.128300467236023, 'num_leaves': 135, 'max_depth': 18, 'feature_fraction': 0.6598271012203855, 'bagging_fraction': 0.863687124843785, 'bagging_freq': 1, 'min_data_in_leaf': 13, 'lambda_l1': 1.3619677970626942, 'lambda_l2': 0.02662987166634799}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.451807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0393012\n",
      "[100]\tvalid_0's binary_logloss: 0.0372749\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0372749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:15:44,620] Trial 72 finished with value: 0.9919408309841683 and parameters: {'learning_rate': 0.1278389256083158, 'num_leaves': 135, 'max_depth': 18, 'feature_fraction': 0.6582554988323507, 'bagging_fraction': 0.8762517991297556, 'bagging_freq': 1, 'min_data_in_leaf': 13, 'lambda_l1': 1.5959887682877134, 'lambda_l2': 0.023624402221424732}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.450940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0393668\n",
      "[100]\tvalid_0's binary_logloss: 0.0373764\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0373764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:16:32,435] Trial 73 finished with value: 0.9919183731087261 and parameters: {'learning_rate': 0.12812621918646439, 'num_leaves': 133, 'max_depth': 18, 'feature_fraction': 0.6575880004241017, 'bagging_fraction': 0.9076357480144859, 'bagging_freq': 1, 'min_data_in_leaf': 13, 'lambda_l1': 1.3685370137346546, 'lambda_l2': 0.02032911619645194}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.460067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.039525\n",
      "[100]\tvalid_0's binary_logloss: 0.0374317\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0374317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:17:30,523] Trial 74 finished with value: 0.9919215813766463 and parameters: {'learning_rate': 0.12791841585493233, 'num_leaves': 120, 'max_depth': 18, 'feature_fraction': 0.6400528101820947, 'bagging_fraction': 0.8788640393306939, 'bagging_freq': 2, 'min_data_in_leaf': 12, 'lambda_l1': 0.7497668312733013, 'lambda_l2': 0.31757032738614216}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.589873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0386269\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's binary_logloss: 0.037675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:18:10,142] Trial 75 finished with value: 0.9917975283503941 and parameters: {'learning_rate': 0.1474006549743685, 'num_leaves': 131, 'max_depth': 19, 'feature_fraction': 0.6696631562640842, 'bagging_fraction': 0.8893739737548807, 'bagging_freq': 1, 'min_data_in_leaf': 15, 'lambda_l1': 0.05147598166067647, 'lambda_l2': 0.058923285216934025}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.446286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0418576\n",
      "[100]\tvalid_0's binary_logloss: 0.0374893\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0374893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:19:01,509] Trial 76 finished with value: 0.9918370969880781 and parameters: {'learning_rate': 0.10259029584663354, 'num_leaves': 136, 'max_depth': 20, 'feature_fraction': 0.6830357314229141, 'bagging_fraction': 0.8672427322667924, 'bagging_freq': 1, 'min_data_in_leaf': 18, 'lambda_l1': 1.9734505696200109, 'lambda_l2': 0.020160535238754638}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.445226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0463666\n",
      "[100]\tvalid_0's binary_logloss: 0.0378559\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0378559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:20:05,931] Trial 77 finished with value: 0.9917408489504687 and parameters: {'learning_rate': 0.08543487148199239, 'num_leaves': 128, 'max_depth': 18, 'feature_fraction': 0.7030626741715428, 'bagging_fraction': 0.8258882480812202, 'bagging_freq': 2, 'min_data_in_leaf': 21, 'lambda_l1': 0.22625483462706517, 'lambda_l2': 0.10392859590434922}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.463046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0409188\n",
      "[100]\tvalid_0's binary_logloss: 0.0376161\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0376161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:20:53,997] Trial 78 finished with value: 0.991836027565438 and parameters: {'learning_rate': 0.12686057254720157, 'num_leaves': 95, 'max_depth': 17, 'feature_fraction': 0.6179598285967779, 'bagging_fraction': 0.9003855290923988, 'bagging_freq': 1, 'min_data_in_leaf': 10, 'lambda_l1': 4.171858459006001, 'lambda_l2': 0.007030300495381473}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.453417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.10735\n",
      "[100]\tvalid_0's binary_logloss: 0.0479142\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0479142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:21:57,998] Trial 79 finished with value: 0.9910863622947244 and parameters: {'learning_rate': 0.041223641184431385, 'num_leaves': 139, 'max_depth': 16, 'feature_fraction': 0.6309895186151996, 'bagging_fraction': 0.959796822272937, 'bagging_freq': 2, 'min_data_in_leaf': 13, 'lambda_l1': 0.6403555399095456, 'lambda_l2': 0.02368053589848846}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.443483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.038799\n",
      "[100]\tvalid_0's binary_logloss: 0.0373778\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0373778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:22:44,850] Trial 80 finished with value: 0.9918841515842427 and parameters: {'learning_rate': 0.14169628124868158, 'num_leaves': 130, 'max_depth': 19, 'feature_fraction': 0.6599349689186456, 'bagging_fraction': 0.8032450321241767, 'bagging_freq': 1, 'min_data_in_leaf': 16, 'lambda_l1': 1.443923453746627, 'lambda_l2': 0.24291187605501038}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.564485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0382993\n",
      "[100]\tvalid_0's binary_logloss: 0.0373106\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0373106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:23:34,814] Trial 81 finished with value: 0.9919536640558495 and parameters: {'learning_rate': 0.16400749486089228, 'num_leaves': 146, 'max_depth': 17, 'feature_fraction': 0.6393468578901256, 'bagging_fraction': 0.8396420261696211, 'bagging_freq': 1, 'min_data_in_leaf': 19, 'lambda_l1': 4.88860391728423, 'lambda_l2': 0.002518514929858723}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.459051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0382526\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's binary_logloss: 0.0373475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:24:19,925] Trial 82 finished with value: 0.9918841515842427 and parameters: {'learning_rate': 0.1643479722005809, 'num_leaves': 146, 'max_depth': 18, 'feature_fraction': 0.6361160246363081, 'bagging_fraction': 0.8415507572324512, 'bagging_freq': 1, 'min_data_in_leaf': 19, 'lambda_l1': 4.084816601762507, 'lambda_l2': 0.0014128286243187097}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.723206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0380142\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.0376994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:24:53,329] Trial 83 finished with value: 0.9917911118145536 and parameters: {'learning_rate': 0.185082586908596, 'num_leaves': 141, 'max_depth': 15, 'feature_fraction': 0.6769369379137029, 'bagging_fraction': 0.8598052381449801, 'bagging_freq': 1, 'min_data_in_leaf': 84, 'lambda_l1': 0.37202745392623054, 'lambda_l2': 0.0007053550810453169}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.451207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0387371\n",
      "[100]\tvalid_0's binary_logloss: 0.0372733\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0372733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:25:40,399] Trial 84 finished with value: 0.9919237202219265 and parameters: {'learning_rate': 0.14061613501786924, 'num_leaves': 135, 'max_depth': 20, 'feature_fraction': 0.6509096638022535, 'bagging_fraction': 0.8718587298913311, 'bagging_freq': 1, 'min_data_in_leaf': 24, 'lambda_l1': 2.14687475020671, 'lambda_l2': 0.006865843482639088}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.435227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0385188\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's binary_logloss: 0.0377674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:26:14,468] Trial 85 finished with value: 0.9917654456711911 and parameters: {'learning_rate': 0.1665643137094443, 'num_leaves': 124, 'max_depth': 17, 'feature_fraction': 0.6147057710590198, 'bagging_fraction': 0.883178878242446, 'bagging_freq': 1, 'min_data_in_leaf': 12, 'lambda_l1': 0.9574459567673935, 'lambda_l2': 0.034080561038196976}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.446660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0399121\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's binary_logloss: 0.0377216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:27:03,895] Trial 86 finished with value: 0.9917879035466333 and parameters: {'learning_rate': 0.12333109661283802, 'num_leaves': 118, 'max_depth': 19, 'feature_fraction': 0.6421960709855777, 'bagging_fraction': 0.8373929047812189, 'bagging_freq': 2, 'min_data_in_leaf': 21, 'lambda_l1': 3.80051024268627e-08, 'lambda_l2': 0.01283719767388892}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.442020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.142153\n",
      "[100]\tvalid_0's binary_logloss: 0.059497\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.059497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:27:49,772] Trial 87 finished with value: 0.9907708826158933 and parameters: {'learning_rate': 0.03303708233234057, 'num_leaves': 143, 'max_depth': 18, 'feature_fraction': 0.6646841591879827, 'bagging_fraction': 0.823689471040874, 'bagging_freq': 1, 'min_data_in_leaf': 15, 'lambda_l1': 5.397163325184575, 'lambda_l2': 0.08680472263265074}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.475786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0429663\n",
      "[100]\tvalid_0's binary_logloss: 0.0375063\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0375063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:28:38,932] Trial 88 finished with value: 0.9918018060409546 and parameters: {'learning_rate': 0.09549409008269344, 'num_leaves': 147, 'max_depth': 17, 'feature_fraction': 0.6950547650277152, 'bagging_fraction': 0.8065272913122993, 'bagging_freq': 1, 'min_data_in_leaf': 18, 'lambda_l1': 2.0527006211014847, 'lambda_l2': 0.9039224058439213}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.447155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0413201\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.0377281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:29:30,634] Trial 89 finished with value: 0.991785764701353 and parameters: {'learning_rate': 0.10647190648034967, 'num_leaves': 133, 'max_depth': 16, 'feature_fraction': 0.6516757042636844, 'bagging_fraction': 0.914919113091654, 'bagging_freq': 2, 'min_data_in_leaf': 12, 'lambda_l1': 0.060892950029191484, 'lambda_l2': 0.0036066278198417004}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.426376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0390369\n",
      "[100]\tvalid_0's binary_logloss: 0.0373228\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0373228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:30:17,854] Trial 90 finished with value: 0.9919408309841683 and parameters: {'learning_rate': 0.1353444623321492, 'num_leaves': 142, 'max_depth': 19, 'feature_fraction': 0.6085496528599476, 'bagging_fraction': 0.9292854961063257, 'bagging_freq': 1, 'min_data_in_leaf': 21, 'lambda_l1': 2.792381854069501, 'lambda_l2': 0.029389043391721208}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.435406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0392752\n",
      "[100]\tvalid_0's binary_logloss: 0.037308\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.037308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:31:03,014] Trial 91 finished with value: 0.9919226507992864 and parameters: {'learning_rate': 0.1331335580426084, 'num_leaves': 138, 'max_depth': 19, 'feature_fraction': 0.6100406750466182, 'bagging_fraction': 0.8595769842918723, 'bagging_freq': 1, 'min_data_in_leaf': 15, 'lambda_l1': 3.761882084357218, 'lambda_l2': 0.03063230533164433}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.453570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.038251\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's binary_logloss: 0.037579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:31:39,966] Trial 92 finished with value: 0.9918167779579161 and parameters: {'learning_rate': 0.1540022714750474, 'num_leaves': 143, 'max_depth': 20, 'feature_fraction': 0.626241687749346, 'bagging_fraction': 0.9339967473644882, 'bagging_freq': 1, 'min_data_in_leaf': 22, 'lambda_l1': 0.8994809567928849, 'lambda_l2': 0.01475883814903517}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.475725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.308494\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.196707\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.196707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:32:01,670] Trial 93 finished with value: 0.9586571901561785 and parameters: {'learning_rate': 0.11858879829519207, 'num_leaves': 147, 'max_depth': 3, 'feature_fraction': 0.6407743964952916, 'bagging_fraction': 0.976976164830512, 'bagging_freq': 1, 'min_data_in_leaf': 10, 'lambda_l1': 6.3828517248412915, 'lambda_l2': 0.007717524322857128}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.443142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0380821\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's binary_logloss: 0.0373716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:32:44,464] Trial 94 finished with value: 0.991937622716248 and parameters: {'learning_rate': 0.1790437947692983, 'num_leaves': 140, 'max_depth': 17, 'feature_fraction': 0.6036729755889592, 'bagging_fraction': 0.8926680395064653, 'bagging_freq': 1, 'min_data_in_leaf': 19, 'lambda_l1': 3.213200991922745, 'lambda_l2': 0.0019485714521611023}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.433363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0390198\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.0376004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:33:24,909] Trial 95 finished with value: 0.9918221250711166 and parameters: {'learning_rate': 0.13706955586798647, 'num_leaves': 128, 'max_depth': 18, 'feature_fraction': 0.6218183892484263, 'bagging_fraction': 0.8769680488287744, 'bagging_freq': 1, 'min_data_in_leaf': 25, 'lambda_l1': 0.482582010967256, 'lambda_l2': 0.0435087327889616}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.424268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0383348\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.0375459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:34:02,969] Trial 96 finished with value: 0.9919023317691245 and parameters: {'learning_rate': 0.1532651927405808, 'num_leaves': 136, 'max_depth': 19, 'feature_fraction': 0.6697623120845845, 'bagging_fraction': 0.9061618196122065, 'bagging_freq': 1, 'min_data_in_leaf': 14, 'lambda_l1': 0.19119119735205556, 'lambda_l2': 0.1495373303659902}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.426451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0381203\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's binary_logloss: 0.0374317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:34:48,231] Trial 97 finished with value: 0.9919237202219265 and parameters: {'learning_rate': 0.18567645623144416, 'num_leaves': 144, 'max_depth': 16, 'feature_fraction': 0.6271640101519085, 'bagging_fraction': 0.8437404359356693, 'bagging_freq': 1, 'min_data_in_leaf': 17, 'lambda_l1': 1.7501577699622417, 'lambda_l2': 4.473353878981762}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.168399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0410837\n",
      "[100]\tvalid_0's binary_logloss: 0.0379016\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0379016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:35:48,556] Trial 98 finished with value: 0.9916456703354992 and parameters: {'learning_rate': 0.11121207680020556, 'num_leaves': 148, 'max_depth': 20, 'feature_fraction': 0.9326309250420505, 'bagging_fraction': 0.8625568886110985, 'bagging_freq': 2, 'min_data_in_leaf': 12, 'lambda_l1': 6.013324617782155, 'lambda_l2': 0.004901922576257384}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.413607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.0381206\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.0375522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-18 22:36:26,683] Trial 99 finished with value: 0.9918499300597593 and parameters: {'learning_rate': 0.17269567382126966, 'num_leaves': 132, 'max_depth': 18, 'feature_fraction': 0.6542568137621558, 'bagging_fraction': 0.92654232989455, 'bagging_freq': 1, 'min_data_in_leaf': 20, 'lambda_l1': 1.0144985510309017, 'lambda_l2': 0.07023896507863077}. Best is trial 58 with value: 0.9919675665501709.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial parameters: {'learning_rate': 0.1570089046776225, 'num_leaves': 136, 'max_depth': 19, 'feature_fraction': 0.622981192126568, 'bagging_fraction': 0.8970254429615686, 'bagging_freq': 1, 'min_data_in_leaf': 10, 'lambda_l1': 2.6912461632162645, 'lambda_l2': 0.015406264409918633}\n",
      "Best accuracy: 0.99\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.622981192126568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.622981192126568\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.015406264409918633, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015406264409918633\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6912461632162645, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6912461632162645\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8970254429615686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8970254429615686\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.622981192126568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.622981192126568\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.015406264409918633, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015406264409918633\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6912461632162645, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6912461632162645\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8970254429615686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8970254429615686\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1193768, number of negative: 988093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.184527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2181861, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.547133 -> initscore=0.189093\n",
      "[LightGBM] [Info] Start training from score 0.189093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.622981192126568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.622981192126568\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.015406264409918633, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015406264409918633\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6912461632162645, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6912461632162645\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8970254429615686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8970254429615686\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Final accuracy on validation set: 99.20%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#model\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters for tuning\n",
    "    param = {\n",
    "        'objective': 'binary',  # Binary classification\n",
    "        'metric': 'binary_logloss',  # Evaluation metric\n",
    "        'boosting_type': 'gbdt',  # Type of boosting\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 20),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.6, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.6, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),  # L1 regularization\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0)   # L2 regularization\n",
    "    }\n",
    "\n",
    "    # Create dataset for LightGBM\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid, reference=train_data)\n",
    "    \n",
    "    # Train the model\n",
    "    model = lgb.train(param, train_data, valid_sets=[valid_data],callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=3), lgb.log_evaluation(50)]\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    preds = model.predict(X_valid)\n",
    "    preds = [1 if p >= 0.5 else 0 for p in preds]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_valid, preds)\n",
    "    \n",
    "    # Return accuracy as the objective value to maximize\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')  # 'maximize' because we want to maximize accuracy\n",
    "\n",
    "# Start optimization\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best trial's parameters\n",
    "print(f'Best trial parameters: {study.best_trial.params}')\n",
    "print(f'Best accuracy: {study.best_value:.2f}')\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# Train the final model using the best parameters\n",
    "final_model = lgb.LGBMClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = final_model.predict(X_valid)\n",
    "final_accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(f'Final accuracy on validation set: {final_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a049c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T22:37:56.894745Z",
     "iopub.status.busy": "2024-08-18T22:37:56.894333Z",
     "iopub.status.idle": "2024-08-18T22:38:32.100597Z",
     "shell.execute_reply": "2024-08-18T22:38:32.099629Z"
    },
    "papermill": {
     "duration": 35.39122,
     "end_time": "2024-08-18T22:38:32.103194",
     "exception": false,
     "start_time": "2024-08-18T22:37:56.711974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.622981192126568, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.622981192126568\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.015406264409918633, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015406264409918633\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.6912461632162645, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6912461632162645\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8970254429615686, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8970254429615686\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "y_final = final_model.predict(test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a52df016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T22:38:32.326787Z",
     "iopub.status.busy": "2024-08-18T22:38:32.326038Z",
     "iopub.status.idle": "2024-08-18T22:38:32.334282Z",
     "shell.execute_reply": "2024-08-18T22:38:32.333366Z"
    },
    "papermill": {
     "duration": 0.121502,
     "end_time": "2024-08-18T22:38:32.336435",
     "exception": false,
     "start_time": "2024-08-18T22:38:32.214933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54c3963b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T22:38:32.549498Z",
     "iopub.status.busy": "2024-08-18T22:38:32.548618Z",
     "iopub.status.idle": "2024-08-18T22:38:32.567849Z",
     "shell.execute_reply": "2024-08-18T22:38:32.566901Z"
    },
    "papermill": {
     "duration": 0.128249,
     "end_time": "2024-08-18T22:38:32.570204",
     "exception": false,
     "start_time": "2024-08-18T22:38:32.441955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_final_replaced = np.where(y_final == 0, 'e', 'p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e089ee8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T22:38:32.782675Z",
     "iopub.status.busy": "2024-08-18T22:38:32.782322Z",
     "iopub.status.idle": "2024-08-18T22:38:32.788552Z",
     "shell.execute_reply": "2024-08-18T22:38:32.787587Z"
    },
    "papermill": {
     "duration": 0.116659,
     "end_time": "2024-08-18T22:38:32.790952",
     "exception": false,
     "start_time": "2024-08-18T22:38:32.674293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['e', 'p', 'p', ..., 'p', 'e', 'e'], dtype='<U1')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49656051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T22:38:33.005844Z",
     "iopub.status.busy": "2024-08-18T22:38:33.005477Z",
     "iopub.status.idle": "2024-08-18T22:38:33.709836Z",
     "shell.execute_reply": "2024-08-18T22:38:33.708921Z"
    },
    "papermill": {
     "duration": 0.815243,
     "end_time": "2024-08-18T22:38:33.712293",
     "exception": false,
     "start_time": "2024-08-18T22:38:32.897050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission1 = pd.read_csv(r'/kaggle/input/playground-series-s4e8/sample_submission.csv')\n",
    "submission1['class'] = y_final_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "334c78c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T22:38:33.937680Z",
     "iopub.status.busy": "2024-08-18T22:38:33.937118Z",
     "iopub.status.idle": "2024-08-18T22:38:36.710205Z",
     "shell.execute_reply": "2024-08-18T22:38:36.708985Z"
    },
    "papermill": {
     "duration": 2.892887,
     "end_time": "2024-08-18T22:38:36.712885",
     "exception": false,
     "start_time": "2024-08-18T22:38:33.819998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission1.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656726a",
   "metadata": {
    "papermill": {
     "duration": 0.108082,
     "end_time": "2024-08-18T22:38:36.927407",
     "exception": false,
     "start_time": "2024-08-18T22:38:36.819325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9045607,
     "sourceId": 76727,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4795.525354,
   "end_time": "2024-08-18T22:38:39.765606",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-18T21:18:44.240252",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
